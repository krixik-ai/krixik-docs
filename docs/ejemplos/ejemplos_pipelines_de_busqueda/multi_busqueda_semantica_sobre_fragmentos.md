<a href="https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/examples/search_pipeline_examples/multi_snippet_semantic_search.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## *Pipeline* Multimodular: B√∫squeda Sem√°ntica Sobre Fragmentos
[üá∫üá∏ English version of this document](https://krixik-docs.readthedocs.io/latest/examples/search_pipeline_examples/multi_snippet_semantic_search/)

Este documento detalla un *pipeline* multimodular que recibe fragmentos de texto en un archivo JSON y habilita [`b√∫squeda sem√°ntica`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md) sobre ellos.

El documento se divide en las siguientes secciones:

- [Monta tu *Pipeline*](#monta-tu-pipeline)
- [Procesa un Archivo de Entrada](#procesa-un-archivo-de-entrada)
- [B√∫squeda Sem√°ntica](#busqueda-semantica)

### Monta tu *Pipeline*

Para lograr lo arriba descrito, monta un pipeline que consiste de los siguientes m√≥dulos en secuencia:

- Un m√≥dulo [`text-embedder` (encaje l√©xico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md).

- Un m√≥dulo [`vector-db` (base de datos vectorial)](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md).

Para esto usar√°s el m√©todo [`create_pipeline`](../../sistema/creacion_de_pipelines/creacion_de_pipelines.md) de la siguiente manera:


```python
# crear el pipeline descrito
pipeline = krixik.create_pipeline(name="multi_busqueda_semantica_sobre_fragmentos", module_chain=["text-embedder", "vector-db"])
```

### Procesa un Archivo de Entrada

El formato de entrada de este *pipeline* es un archivo JSON (dado que ese es el formato de entrada de su [primer m√≥dulo](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md)). Las entradas JSON siempre deben seguir un [formato espec√≠fico](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/formato_JSON_entrada.md); de lo contrario, el m√©todo [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md) no funcionar√°.

Examina el archivo de prueba antes de continuar:


```python
# examina el archivo de entrada
with open(data_dir + "input/1984_fragmentos.json", "r") as file:
    print(file.read())
```

    [{"snippet": "It was a bright cold day in April, and the clocks were striking thirteen.", "line_numbers": [1]}, {"snippet": "Winston Smith, his chin nuzzled into his breast in an effort to escape the\nvile wind, slipped quickly through the glass doors of Victory Mansions,\nthough not quickly enough to prevent a swirl of gritty dust from entering\nalong with him.", "line_numbers": [2, 3, 4, 5]}]


Usar√°s los modelos predeterminados en este *pipeline*, as√≠ que el argumento [`modules`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md#seleccion-de-modelo-por-medio-del-argumento-modules) del m√©todo [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md) no har√° falta.


```python
# procesa el archivo a trav√©s del pipeline seg√∫n lo arriba descrito
process_output = pipeline.process(
    local_file_path=data_dir + "input/1984_fragmentos.json",  # la ruta de archivo inicial en la que yace el archivo de entrada
    local_save_directory=data_dir + "output",  # el directorio local en el que se guardar√° el archivo de salida
    expire_time=60 * 30,  # data de este proceso se eliminar√° del sistema Krixik en 30 minutos
    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario
    verbose=False,  # no mostrar actualizaciones de proceso al ejecutar el c√≥digo
)
```

Reproduce la salida de este proceso con el siguiente c√≥digo. Para aprender m√°s sobre cada componente de la salida, estudia la documentaci√≥n del m√©todo [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md).

Dado que la salida de este modelo/m√≥dulo es un archivo de base de datos [FAISS](https://github.com/facebookresearch/faiss), `process_output` se muestra como "null". Sin embargo, el archivo de salida se ha guardado en la ubicaci√≥n indicada bajo `process_output_files`. El `file_id` del archivo procesado es el prefijo del nombre del archivo de salida en esta ubicaci√≥n.


```python
# n√≠tidamente reproduce la salida de este proceso
print(json.dumps(process_output, indent=2))
```

    {
      "status_code": 200,
      "pipeline": "multi_snippets_semantic_search",
      "request_id": "df80b7bd-d593-4cdd-bc39-4d2bdd18788e",
      "file_id": "f52906bb-eca6-408c-a929-504ea8954e76",
      "message": "SUCCESS - output fetched for file_id f52906bb-eca6-408c-a929-504ea8954e76.Output saved to location(s) listed in process_output_files.",
      "warnings": [],
      "process_output": null,
      "process_output_files": [
        "../../../data/output/f52906bb-eca6-408c-a929-504ea8954e76.faiss"
      ]
    }


### Busqueda Semantica

El m√©todo [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md) de Krixik habilita b√∫squeda sem√°ntica sobre documentos procesados a trav√©s de ciertos *pipelines*. Dado que el m√©todo [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md) hace [`embedding` (encaje l√©xico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) con la consulta y luego lleva a cabo la b√∫squeda, solo se puede usar con *pipelines* que de manera consecutiva contienen los m√≥dulos [`text-embedder` (encaje l√©xico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) y [`vector-db` (base de datos vectorial)](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md).

Ya que tu *pipeline* satisface esta condici√≥n tiene acceso al m√©todo [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md). √ösalo de la siguiente manera para consultar el texto con lengua natural:


```python
# haz b√∫squeda sem√°ntica sobre el texto procesado por el pipeline
semantic_output = pipeline.semantic_search(query="it was cold night", file_ids=[process_output["file_id"]])

# n√≠tidamente reproduce la salida de esta b√∫squeda
print(json.dumps(semantic_output, indent=2))
```

    {
      "status_code": 200,
      "request_id": "4df32bdf-bb82-44d4-8151-ffaf2fc99c18",
      "message": "Successfully queried 1 user file.",
      "warnings": [],
      "items": [
        {
          "file_id": "f52906bb-eca6-408c-a929-504ea8954e76",
          "file_metadata": {
            "file_name": "krixik_generated_file_name_xongatwbce.json",
            "symbolic_directory_path": "/etc",
            "file_tags": [],
            "num_vectors": 2,
            "created_at": "2024-06-05 15:31:41",
            "last_updated": "2024-06-05 15:31:41"
          },
          "search_results": [
            {
              "snippet": "It was a bright cold day in April, and the clocks were striking thirteen.",
              "line_numbers": [
                1
              ],
              "distance": 0.236
            },
            {
              "snippet": "Winston Smith, his chin nuzzled into his breast in an effort to escape the\nvile wind, slipped quickly through the glass doors of Victory Mansions,\nthough not quickly enough to prevent a swirl of gritty dust from entering\nalong with him.",
              "line_numbers": [
                2,
                3,
                4,
                5
              ],
              "distance": 0.429
            }
          ]
        }
      ]
    }

