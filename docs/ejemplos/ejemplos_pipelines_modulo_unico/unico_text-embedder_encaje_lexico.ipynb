{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/examples/single_module_pipelines/single_text-embedder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# preparación de demo - incuye instanciación de secretos, instalación de requerimientos, y definición de rutas\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # si estás usando este notebook en Google Colab, ingresa tus secretos acá\n",
    "    MY_API_KEY = \"TU_API_KEY_VA_AQUI\"\n",
    "    MY_API_URL = \"TU_API_URL_VA_AQUI\"\n",
    "\n",
    "    # si estás usando este notebook en Google Colab, instala requerimientos y descarga los subdirectorios requeridos\n",
    "    # instala el cliente Python de Krixik\n",
    "    !pip install krixik\n",
    "\n",
    "    # instala github-clone, que permite clonación fácil de los subdirectorios del repositorio de documentación XXX\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clona los conjuntos de datos\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone XXXX #(in english it's https://github.com/krixik-ai/krixik-docs/tree/main/data)\n",
    "    else:\n",
    "        print(\"ya se clonaron los conjuntos de datos de documentación!\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # crea directorio de salidas\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/salidas\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # descarga utilidades\n",
    "    if not Path(\"utilities\").is_dir():\n",
    "        !ghclone XXXX # (in english it's https://github.com/krixik-ai/krixik-docs/tree/main/utilities)\n",
    "    else:\n",
    "        print(\"ya has clonado las utilidades de documentación!\")\n",
    "else:\n",
    "    # si estás usando una descarga local de la documentación, define las rutas relativas a la estructura local de la documentación\n",
    "    # importa utilidades\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # si estás usando este notebook localmente desde el repositorio de documentación Krixik, carga tus secretos de un archivo .env ubicado en la base del repositorio de documentación\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "\n",
    "# carga 'reset'\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "\n",
    "# importa Krixik e inicializa sesión con tus secretos personales\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pipeline* de Módulo Único: `text-embedder` (Encaje Léxico)\n",
    "\n",
    "Este documento presenta una guía de cómo ensamblar y consumir un *pipeline* de módulo único que solo incluye un módulo [`text-embedder` (encaje léxico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md). Se divide en las siguientes secciones:\n",
    "\n",
    "- [Monta tu *Pipeline*](#monta-tu-pipeline)\n",
    "- [Formato de Entrada Requerido](#formato-de-entrada-requerido)\n",
    "- [Cómo Usar el Modelo Predeterminado](#como-usar-el-modelo-predeterminado)\n",
    "- [Examina Salidas de Proceso Localmente](#examina-salidas-de-proceso-localmente)\n",
    "- [Cómo Usar un Modelo No-Predeterminado](#como-usar-un-modelo-no-predeterminado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monta tu *Pipeline*\n",
    "\n",
    "Primero crea un *pipeline* de módulo único con un módulo [`text-embedder` (encaje léxico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md).\n",
    "\n",
    "Usa el método [`create_pipeline`](../../sistema/creacion_de_pipelines/creacion_de_pipelines.md) para esto, incluyendo solamente una referencia de módulo [`text-embedder`](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) en el argumento `module_chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un pipeline con un solo módulo text-embedder\n",
    "pipeline = krixik.create_pipeline(name=\"unico_text-embedder_1\",\n",
    "                                  module_chain=[\"text-embedder\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato de Entrada Requerido\n",
    "\n",
    "El módulo [`text-embedder` (encaje léxico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) recibe entradas con formato JSON. Las entradas JSON deben respetar [esta estructura](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/formato_JSON_entrada.md).\n",
    "\n",
    "El archivo JSON de entrada también puede incluir, acompañando a cada fragmento, un par clave-valor en el que la clave es el *string* `\"line numbers\"` y el valor es una lista de *int* que indica cada número de línea en el documento original en el que yacía ese fragmento de texto. Esto te puede ayudar a identificar qué línea del documento original está incrustada en cada vector.\n",
    "\n",
    "Antes de procesar un archivo de entrada—uno válido para este *pipeline*—examínalo con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "    \"line_numbers\": [\n",
      "      1\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "    \"line_numbers\": [\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# examina el contenido de un archivo de entrada válido\n",
    "with open(data_dir + \"input/1984_fragmentos.json\", \"r\") as file:\n",
    "    print(json.dumps(json.load(file), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como Usar el Modelo Predeterminado\n",
    "\n",
    "Ahora procesa el archivo usando el modelo [predeterminado](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md#modelos-disponibles-en-el-modulo-text-embedder) del módulo [`text embedder` (encaje léxico)](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md): [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "Dado que este es el modelo predeterminado, no hace falta que especifiques qué modelo quieres usar a través del argumento opcional [`modules`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md#seleccion-de-modelo-por-medio-del-argumento-modules) del método [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md).\n",
    "\n",
    "Más adelante en este documento procesarás el mismo archivo, pero ahí especificando si el proceso será o no con cuantificación vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procesa el archivo con el modelo predeterminado\n",
    "process_output = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/1984_fragmentos.json\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardará el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminará del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False, # no mostrar actualizaciones de proceso al ejecutar el código\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida del proceso se reproduce con el siguiente código. Para aprender más sobre cada componente de esta salida, revisa la documentación del método [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md).\n",
    "\n",
    "El archivo de salida se ha guardado en la ubicación indicada bajo `process_output_files`. El `file_id` del archivo procesado es el prefijo del nombre del archivo de salida en esta ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"single_text-embedder-1\",\n",
      "  \"request_id\": \"ce2e57ce-c2be-49ac-8d43-59e6db2bcf25\",\n",
      "  \"file_id\": \"ce4ddfa5-12c6-4dcb-86af-4f6d30ed6188\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id ce4ddfa5-12c6-4dcb-86af-4f6d30ed6188.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/ce4ddfa5-12c6-4dcb-86af-4f6d30ed6188.npy\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nítidamente reproduce la salida de este proceso\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examina Salidas de Proceso Localmente\n",
    "\n",
    "Los archivos de salida en formato NPY que contienen incrustaciones de vectores de los datos de entrada se pueden examinar con el siguiente código. Para que el ejercicio sea claro, en este ejemplo sólo se imprimirá la forma, y no el contenido, del arreglo devuelto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "# examina la salida vectorial\n",
    "import numpy as np\n",
    "\n",
    "vectors = np.load(process_output[\"process_output_files\"][0])\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta salida significa que el arreglo tiene 2 filas con 384 valores en cada fila.\n",
    "\n",
    "En el contexto del archivo de entrada, la primera fila es la forma vectorizada del primer fragmento: \"It was a bright cold day in April, and the clocks were striking thirteen.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como Usar un Modelo No-Predeterminado\n",
    "\n",
    "Para usar un modelo [no-predeterminado](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md#modelos-disponibles-en-el-modulo-text-embedder) como [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2), debes especificarlo a través del argumento [`modules`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md#seleccion-de-modelo-por-medio-del-argumento-modules) al usar el método [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md). Como indica la [documentación](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) de este módulo, también puedes especificar si quieres usar la versión del modelo con o sin cuantificación vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procesa el archivo con un modelo no-predeterminado\n",
    "process_output = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/1984_fragmentos.json\",  # todos los argumentos (salvo modules) son iguales que antes\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,\n",
    "    wait_for_process=True,\n",
    "    verbose=False,\n",
    "    modules={\"text-embedder\": {\"model\": \"all-mpnet-base-v2\", \"params\": {\"quantize\": False}}}, # especifica un modelo no-predeterminado (y sus parámetros) para este proceso\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar código como el anterior para reproducir y revisar la salida de este proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"single_text-embedder-1\",\n",
      "  \"request_id\": \"f53c93da-cf1b-41e0-a578-16dc62736ed4\",\n",
      "  \"file_id\": \"1dcbde04-d4f2-414f-acaf-577c355bbb88\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 1dcbde04-d4f2-414f-acaf-577c355bbb88.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/1dcbde04-d4f2-414f-acaf-577c355bbb88.npy\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nítidamente reproduce la salida de este proceso\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# elimina todos los datos procesados pertenecientes a este pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
