{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/examples/single_module_pipelines/single_vector-db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# preparación de demo - incuye instanciación de secretos, instalación de requerimientos, y definición de rutas\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # si estás usando este notebook en Google Colab, ingresa tus secretos acá\n",
    "    MY_API_KEY = \"TU_API_KEY_VA_AQUI\"\n",
    "    MY_API_URL = \"TU_API_URL_VA_AQUI\"\n",
    "\n",
    "    # si estás usando este notebook en Google Colab, instala requerimientos y descarga los subdirectorios requeridos\n",
    "    # instala el cliente Python de Krixik\n",
    "    !pip install krixik\n",
    "\n",
    "    # instala github-clone, que permite clonación fácil de los subdirectorios del repositorio de documentación XXX\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clona los conjuntos de datos\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone XXXX #(in english it's https://github.com/krixik-ai/krixik-docs/tree/main/data)\n",
    "    else:\n",
    "        print(\"ya se clonaron los conjuntos de datos de documentación!\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # crea directorio de salidas\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/salidas\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # descarga utilidades\n",
    "    if not Path(\"utilities\").is_dir():\n",
    "        !ghclone XXXX # (in english it's https://github.com/krixik-ai/krixik-docs/tree/main/utilities)\n",
    "    else:\n",
    "        print(\"ya has clonado las utilidades de documentación!\")\n",
    "else:\n",
    "    # si estás usando una descarga local de la documentación, define las rutas relativas a la estructura local de la documentación\n",
    "    # importa utilidades\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # si estás usando este notebook localmente desde el repositorio de documentación Krixik, carga tus secretos de un archivo .env ubicado en la base del repositorio de documentación\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "\n",
    "# carga 'reset'\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "\n",
    "# importa Krixik e inicializa sesión con tus secretos personales\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pipeline* de Módulo Único: `vector-db` (Base de Datos Vectorial)\n",
    "\n",
    "Este documento presenta una guía de cómo ensamblar y consumir un *pipeline* de módulo único que solo incluye un módulo [`vector-db` (base de datos vectorial)](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md).\n",
    "\n",
    "Ten en cuenta que usar este módulo como módulo único no genera un *pipeline* particularmente fácil de usar, dado que por separado debes tener los archivos NPY que procesarás. Sugerimos detallar este [ejemplo de *pipeline*](../ejemplos_pipelines_de_busqueda/multi_busqueda_semantica_basica.md) y este [otro ejemplo de *pipeline*](../ejemplos_pipelines_de_busqueda/multi_busqueda_semantica_sobre_fragmentos.md), que respectivamente toman archivos de entrada TXT y JSON y habilitan [búsqueda semántica](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md) (también llamada búsqueda vectorial) sobre ellos.\n",
    "\n",
    "El documento se divide en las siguientes secciones:\n",
    "\n",
    "- [Monta tu *Pipeline*](#monta-tu-pipeline)\n",
    "- [Formato de Entrada Requerido](#formato-de-entrada-requerido)\n",
    "- [Cómo Usar el Modelo Predeterminado](#como-usar-el-modelo-predeterminado)\n",
    "- [El Método `semantic_search`](#el-metodo-semantic_search)\n",
    "- [Consulta Bases de Datos de Salida Localmente](#consulta-bases-de-datos-de-salida-localmente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monta tu *Pipeline*\n",
    "\n",
    "Primero crea un *pipeline* de módulo único con un módulo [`vector-db` (base de datos vectorial)](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md).\n",
    "\n",
    "Usa el método [`create_pipeline`](../../sistema/creacion_de_pipelines/creacion_de_pipelines.md) para esto, incluyendo solamente una referencia de módulo [`vector-db`](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md) en el argumento `module_chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un pipeline con un solo módulo vector-db\n",
    "pipeline = krixik.create_pipeline(name=\"unico_vector-db_1\",\n",
    "                                  module_chain=[\"vector-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato de Entrada Requerido\n",
    "\n",
    "El módulo [`vector-db` (base de datos vectorial)](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md) acepta archivos NPY como entradas. Estos archivos consisten de un solo arreglo NumPy. Cada fila del arreglo es un vector que el módulo [`vector-db`](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md) luego indexa para búsqueda semántica (también conocida como búsqueda vectorial).\n",
    "\n",
    "Antes de procesar un archivo de entrada—uno válido para este *pipeline*—examínalo con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examina el contenido de un archivo de entrada válido\n",
    "import numpy as np\n",
    "\n",
    "np.load(data_dir + \"input/vectores.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como Usar el Modelo Predeterminado\n",
    "\n",
    "Ahora procesa el archivo usando el modelo [predeterminado](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md#modelos-disponibles-en-el-modulo-vector-db) del módulo [`vector-db`](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md): [`faiss`](https://github.com/facebookresearch/faiss). Por lo pronto, este es el único modelo en este módulo.\n",
    "\n",
    "Dado que este es el modelo predeterminado, no hace falta que especifiques qué modelo quieres usar a través del argumento opcional [`modules`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md#seleccion-de-modelo-por-medio-del-argumento-modules) del método [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procesa el archivo con el modelo predeterminado\n",
    "process_output = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/vectores.npy\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardará el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminará del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False, # no mostrar actualizaciones de proceso al ejecutar el código\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida del proceso se reproduce con el siguiente código. Para aprender más sobre cada componente de esta salida, revisa la documentación del método [`process`](../../sistema/parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md).\n",
    "\n",
    "Dado que la salida de este modelo/módulo es un archivo de base de datos [FAISS](https://github.com/facebookresearch/faiss), `process_output` se muestra como \"null\". Sin embargo, el archivo de salida se ha guardado en la ubicación indicada bajo `process_output_files`. El `file_id` del archivo procesado es el prefijo del nombre del archivo de salida en esta ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"modules-vector-db-docs\",\n",
      "  \"request_id\": \"536c9e0b-41ed-4c41-99dc-11cdabf32ecc\",\n",
      "  \"file_id\": \"63c88fdc-8b62-4f74-af20-c4816ee0bb88\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 63c88fdc-8b62-4f74-af20-c4816ee0bb88.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/63c88fdc-8b62-4f74-af20-c4816ee0bb88.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nítidamente reproduce la salida de este proceso\n",
    "print(json.dumps(process_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El Metodo `semantic_search`\n",
    "\n",
    "Cualquier *pipeline* que contiene un módulo [`vector-db`](../../modulos/modulos_de_bases_de_datos/modulo_vector-db_base_de_datos_vectorial.md) precedido de un módulo [`text-embedder`](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md) tiene acceso al método [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md). Este te permite hacer búsqueda semántica sobre las bases de datos vectoriales que has creado.\n",
    "\n",
    "Dado que el *pipeline* de módulo único que acabas de crear carece de un módulo [`text-embedder`](../../modulos/modulos_ia/modulo_text-embedder_encaje_lexico.md), el método [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md) no funcionará con él. Revisa la documentación de [este ejemplo](../../ejemplos/ejemplos_pipelines_de_busqueda/multi_busqueda_semantica_basica.md) de *pipeline* o de [este otro ejemplo](../../ejemplos/ejemplos_pipelines_de_busqueda/multi_busqueda_semantica_sobre_fragmentos.md) de *pipeline*, los cuales cumplen los requerimientos para este método: el primero recibe archivos TXT, y el segundo recibe archivos JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta Bases de Datos de Salida Localmente\n",
    "\n",
    "Además de lo que ofrece el método [`semantic_search`](../../sistema/metodos_de_busqueda/metodo_semantic_search_busqueda_semantica.md), puedes  hacer consultas **localmente** sobre las bases de datos vectoriales que has generado y que cuya ubicación está indicada en `process_output_files`.\n",
    "\n",
    "La siguiente es una función para localmente hacer búsquedas semánticas sobre el archivo de base de datos antes devuelto.\n",
    "\n",
    "Nota: Para ejecutar el siguiente código tendrás que instalar la librería `FAISS`. Dependiendo de tus especificaciones locales, instala [faiss-cpu](https://pypi.org/project/faiss-cpu/) o [faiss-gpu](https://pypi.org/project/faiss-gpu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs_venv/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs_venv/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# asegúrate que has instalado faiss (faiss-cpu or faiss-gpu)\n",
    "!pip install faiss-cpu\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def query_vector_db(query_vector: np.ndarray, k: int, db_file_path: str) -> Tuple[list, list]:\n",
    "    # subir base de datos vectorial\n",
    "    faiss_index = faiss.read_index(db_file_path)\n",
    "\n",
    "    # ejecutar consulta\n",
    "    similarities, indices = faiss_index.search(query_vector, k)\n",
    "    distances = 1 - similarities\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora consulta tu base de datos con la función anterior y un pequeño arreglo de prueba. Los resultados están reproducidos tras el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input query vector: [0 1]\n",
      "closest vector from original: [0 1]\n",
      "distance from query to this vector: 0.0\n",
      "second closest vector from original: [1 1]\n",
      "distance from query to this vector: 0.2928932309150696\n"
     ]
    }
   ],
   "source": [
    "# haz una búsqueda de prueba con la funcion de búsqueda arriba presentada\n",
    "original_vectors = np.load(data_dir + \"input/vectors.npy\")\n",
    "query_vector = np.array([[0, 1]])\n",
    "distances, indices = query_vector_db(query_vector, 2, process_output[\"process_output_files\"][0])\n",
    "print(f\"vector de entrada de consulta: {query_vector[0]}\")\n",
    "print(f\"vector más cercano al original: {original_vectors[indices[0][0]]}\")\n",
    "print(f\"distancia del vector de búsqueda a este vector: {distances[0][0]}\")\n",
    "print(f\"segundo vector más cercano al original: {original_vectors[indices[0][1]]}\")\n",
    "print(f\"distancia del vector de búsqueda a este vector: {distances[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# elimina todos los datos procesados pertenecientes a este pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
