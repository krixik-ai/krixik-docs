{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/modules/ai_modules/text-embedder_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# demo setup - including secrets instantiation, requirements installation, and path setting\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # if running this notebook in Google Colab - make sure to enter your secrets\n",
    "    MY_API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "    MY_API_URL = \"YOUR_API_URL_HERE\"\n",
    "\n",
    "    # if running this notebook on Google Colab - install requirements and pull required subdirectories\n",
    "    # install Krixik python client\n",
    "    !pip install krixik\n",
    "\n",
    "    # install github clone - allows for easy cloning of subdirectories from docs repo: https://github.com/krixik-ai/krixik-docs\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clone datasets\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/main/data\n",
    "    else:\n",
    "        print(\"docs datasets already cloned!\")\n",
    "\n",
    "    # define data dir\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # create output dir\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "else:\n",
    "    # if running local pull of docs - set paths relative to local docs structure\n",
    "    # import utilities\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define data_dir\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # if running this notebook locally from Krixik docs repo - load secrets from a .env placed at the base of the docs repo\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "# import Krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `text-embedder` Module\n",
    "[ðŸ‡¨ðŸ‡´ VersiÃ³n en espaÃ±ol de este documento](https://krixik-docs.readthedocs.io/es-main/modulos/modulos_ia/modulo_text-embedder_encaje_lexico/)\n",
    "\n",
    "The `text-embedder` module takes one or more text snippets, transforms each into a vector (a mathematical representation of the snippet that retains its meaning), and returns an array containing every generated vector. Vector arrays can then be fed into a vector database to enable semantic (a.k.a. vector) search.\n",
    "\n",
    "Much has been written about vector embeddings. For instance, if you're curious, take a look at [this Medium article](https://medium.com/@2twitme/an-intuitive-101-guide-to-vector-embeddings-ffde295c3558) or [this YouTube video](https://www.youtube.com/watch?v=NEreO2zlXDk).\n",
    "\n",
    "This overview of the `text-embedder` module is divided into the following sections:\n",
    "\n",
    "- [Inputs and Outputs of the `text-embedder` Module](#inputs-and-outputs-of-the-text-embedder-module)\n",
    "- [Available Models in the `text-embedder` Module](#available-models-in-the-text-embedder-module)\n",
    "- [Model Parameters in the `text-embedder` Module](#model-parameters-in-the-text-embedder-module)\n",
    "- [Input File Size Limit](#input-file-size-limit)\n",
    "- [A Single-Module Pipeline for the `text-embedder` Module](#a-single-module-pipeline-for-the-text-embedder-module)\n",
    "- [Further Information on `text-embedder` Module IO and Clickability](#further-information-on-text-embedder-module-io-and-clickability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and Outputs of the `text-embedder` Module\n",
    "\n",
    "The `text-embedder` module accepts JSON file input. The input JSON must respect [this format](../../system/parameters_processing_files_through_pipelines/JSON_input_format.md).\n",
    "\n",
    "The JSON file may optionally also include, along with each snippet, a key-value pair in which the key is the string `\"line numbers\"` and the value is an integer list of every line number of the original document that the snippet is on. This will make it easier for you to identify what document line each vector is an embedding of.\n",
    "\n",
    "The `text-embedder` module returns a vector array in an NPY file.\n",
    "\n",
    "As an example of the `text-embedder` module's input format, take a look at the contents of the following JSON output, printed after the code. This is how an input file must be structured (keep in mind that the `line numbers` key is optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "    \"line_numbers\": [\n",
      "      1\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "    \"line_numbers\": [\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# examine the contents of a valid input file\n",
    "test_file = data_dir + \"input/1984_snippets.json\"\n",
    "with open(test_file, \"r\") as file:\n",
    "    print(json.dumps(json.load(file), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Models in the `text-embedder` Module\n",
    "\n",
    "You can activate any of the following models when using the `text-embedder` module:\n",
    "\n",
    "- [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) (default) [English]\n",
    "\n",
    "- [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) [English]\n",
    "\n",
    "- [all-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) [English]\n",
    "\n",
    "- [multi-qa-MiniLM-L6-cos-v1](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1) [English]\n",
    "\n",
    "- [msmarco-distilbert-dot-v5](https://huggingface.co/sentence-transformers/msmarco-distilbert-dot-v5) [English]\n",
    "\n",
    "Use the [`modules`](../../system/parameters_processing_files_through_pipelines/process_method.md#selecting-models-via-the-modules-argument) argument in the [`process`](../../system/parameters_processing_files_through_pipelines/process_method.md) method to determine what model you'd like active when you process files through the `text-embedder` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters in the `text-embedder` Module\n",
    "\n",
    "All of the `text-embedder` module models are parameterizable. They all take one parameter:\n",
    "\n",
    "- `quantize` (boolean) - If `True`, reduces the number of decimal points in vectors for speed and memory while losing a bit of accuracy (this is a very simplified explanation of what vector quantization is). Defaults to `True`.\n",
    "\n",
    " Consequently, when selecting what model you'll use through the [`process`](../../system/parameters_processing_files_through_pipelines/process_method.md) method's [`modules`](../../system/parameters_processing_files_through_pipelines/process_method.md#selecting-models-via-the-modules-argument) argument, `params` can include a value for `quantize`. For example:\n",
    "\n",
    "```python\n",
    "# example model selection for text-embedder module in process\n",
    "modules={'text-embedder': {\"model\": \"all-mpnet-base-v2\",\n",
    "                           \"params\": {\"quantize\": False}}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input File Size Limit\n",
    "\n",
    "`text-embedder` module input JSON files can currently be no larger than 3MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Single-Module Pipeline for the `text-embedder` Module\n",
    "\n",
    "Please click [here](../../examples/single_module_pipelines/single_text-embedder.md) to visit the `Pipeline Examples` section of our documentation and review an example of a single-module pipeline for the `text-embedder` module.\n",
    "\n",
    "Keep in mind that the output of this pipeline will be an NPY file, which is not human-readable (it's an array of vectors). The `text-embedder` module is easier consumed when paired with a [`vector-db`](../database_modules/vector-db_module.md) module to enable [`semantic (vector) search`](../../system/search_methods/semantic_search_method.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Information on `text-embedder` Module IO and Clickability\n",
    "\n",
    "Please click [here](../../system/convenience_methods/convenience_methods.md) to visit the `Convenience Methods (and More!)` documentation. There you will find two tools to learn more about the `text-embedder` module:\n",
    "\n",
    "- [View Module Input and Output Examples](../../system/convenience_methods/convenience_methods.md#view-module-input-and-output-examples)\n",
    "\n",
    "- [View Module Click Data with the `click_data` Method](../../system/convenience_methods/convenience_methods.md#view-module-click-data-with-the-view_module_click_data-method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
