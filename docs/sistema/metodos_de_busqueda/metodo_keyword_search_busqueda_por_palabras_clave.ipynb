{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/system/search_methods/keyword_search_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# preparaci√≥n de demo - incuye instanciaci√≥n de secretos, instalaci√≥n de requerimientos, y definici√≥n de rutas\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # si est√°s usando este notebook en Google Colab, ingresa tus secretos ac√°\n",
    "    MY_API_KEY = \"TU_API_KEY_VA_AQUI\"\n",
    "    MY_API_URL = \"TU_API_URL_VA_AQUI\"\n",
    "\n",
    "    # si est√°s usando este notebook en Google Colab, instala requerimientos y descarga los subdirectorios requeridos\n",
    "    # instala el cliente Python de Krixik\n",
    "    !pip install krixik\n",
    "\n",
    "    # instala github-clone, que permite clonaci√≥n f√°cil de los subdirectorios del repositorio de documentaci√≥n https://github.com/krixik-ai/krixik-docs\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clona los conjuntos de datos\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/es-main/data\n",
    "    else:\n",
    "        print(\"ya se clonaron los conjuntos de datos de documentaci√≥n!\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # crea directorio de salidas\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/salidas\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "else:\n",
    "    # si est√°s usando una descarga local de la documentaci√≥n, define las rutas relativas a la estructura local de la documentaci√≥n\n",
    "    # importa utilidades\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define la variable 'data_dir' para tus rutas\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # si est√°s usando este notebook localmente desde el repositorio de documentaci√≥n Krixik, carga tus secretos de un archivo .env ubicado en la base del repositorio de documentaci√≥n\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "\n",
    "# importa Krixik e inicializa sesi√≥n con tus secretos personales\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El M√©todo `keyword_search` (B√∫squeda por Palabras Clave)\n",
    "[üá∫üá∏ English version of this document](https://krixik-docs.readthedocs.io/latest/system/search_methods/keyword_search_method/)\n",
    "\n",
    "El m√©todo `keyword_search` de Krixik habilita b√∫squeda por palabras clave sobre documentos procesados a trav√©s de ciertos *pipelines*. La b√∫squeda por palabras clave es algo que los usuarios de internet conocen hace mucho tiempo: una serie de palabras es enviado como la consulta (*the query*), y la b√∫squeda devuelve toda aparici√≥n de cada una de esas palabras. Es muy diferente a [b√∫squeda sem√°ntica](metodo_semantic_search_busqueda_semantica.md).\n",
    "\n",
    "El m√©todo `keyword_search` solo se puede usar con *pipelines* que terminan con el m√≥dulo [`keyword-db`](../../modulos/modulos_de_bases_de_datos/modulo_keyword-db_base_de_datos_de_palabras_clave.md).\n",
    "\n",
    "Esta introducci√≥n al m√©todo `keyword_search` se divide en las siguientes secciones:\n",
    "\n",
    "- [Argumentos del M√©todo keyword_search](#argumentos-del-metodo-keyword_search)\n",
    "- [Ejemplo de Montaje de Pipeline y Procesamiento de Archivo](#ejemplo-de-montaje-de-pipeline-y-procesamiento-de-archivo)\n",
    "- [Ejemplos de B√∫squedas por Palabras Clave](#ejemplos-de-busquedas-por-palabras-clave)\n",
    "- [L√≠mite de Tama√±o de Salidas](#limite-de-tamano-de-salidas)\n",
    "- [Stop Words (Palabras Ignoradas)](#stop-words-palabras-ignoradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argumentos del Metodo `keyword_search`\n",
    "\n",
    "El m√©todo `keyword_search` toma un argumento requerido y al menos uno de varios argumentos opcionales. El argumento requerido es:\n",
    "\n",
    "- `query` (str) - Un *string* que contiene una o m√°s palabras clave separadas por espacios o guiones. Estas palabras se buscar√°n individualmente en el documento se√±alado.\n",
    "\n",
    "Los argumentos opcionales son los mismos argumentos que el m√©todo [`list`](../sistema_de_archivos/metodo_list_lista.md) recibe‚Äîtanto los de metadata como las marcas de tiempo‚Äîas√≠ que [det√°llalos aqu√≠](../sistema_de_archivos/metodo_list_lista.md#argumentos-del-metodo-list-lista) si es necesario. Al igual que con el m√©todo [`list`](../sistema_de_archivos/metodo_list_lista.md), puedes hacer `keyword_search` sobre varios archivos a la vez porque todos los argumentos de metadata se env√≠an al m√©todo `keyword_search` en formato de lista. Todos los elementos de los argumentos opcionales son iguales que para el m√©todo [`list`](../sistema_de_archivos/metodo_list_lista.md), incluyendo el operador comod√≠n * y la ra√≠z global.\n",
    "\n",
    "Si no est√° presente ninguno de estos argumentos opcionales, el m√©todo `keyword_search` no funcionar√° porque no hay d√≥nde buscar.\n",
    "\n",
    "Como el m√©todo [`list`](../sistema_de_archivos/metodo_list_lista.md), el m√©todo `keyword_search` acepta los argumentos opcionales `max_files` y `sort_order`, aunque su funci√≥n cambia un poco:\n",
    "\n",
    "- `max_files` especifica en hasta cu√°ntos archivos se debe buscar. Su valor predeterminado no existe; no habr√≠a un m√°ximo.\n",
    "\n",
    "- `sort_order` ac√° toma dos valores posibles: 'ascending' y 'descending'. Esto determina en qu√© orden se devuelven los archivos sobre los que se ha buscado (en cuanto a su marca de tiempo de creaci√≥n), pero los resultados de palabra clave dentro de cada archivo se devuelven siempre en el orden en que aparecen en el texto. Su valor predeterminado es 'descending'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Montaje de Pipeline y Procesamiento de Archivo\n",
    "\n",
    "Para los ejemplos de este documento usar√°s un *pipeline* que consiste de un solo m√≥dulo [`keyword-db`](../../modulos/modulos_de_bases_de_datos/modulo_keyword-db_base_de_datos_de_palabras_clave.md). Este es el *pipeline* b√°sico de b√∫squeda por palabras clave. Usa el m√©todo [`create_pipeline`](../creacion_de_pipelines/creacion_de_pipelines.md) para crear el *pipeline*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea el pipeline b√°sico para b√∫squeda por palabras clave\n",
    "pipeline = krixik.create_pipeline(name=\"metodo_keyword_search_1_keyword-db\", module_chain=[\"keyword-db\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que el *pipeline* est√° listo puedes [`procesar`](../parametros_y_procesar_archivos_a_traves_de_pipelines/metodo_process_procesar.md) algunos archivos de texto a trav√©s de √©l para que tengas documentos sobre los cuales puedas hacer b√∫squedas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrega cuatro archivos al pipeline que acabas de crear\n",
    "salida_1 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/frankenstein_muy_corto.txt\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardar√° el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminar√° del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False,  # no mostrar actualizaciones de proceso al ejecutar el c√≥digo\n",
    "    symbolic_directory_path=\"/novelas/gotica\",\n",
    "    file_name=\"Frankenstein.txt\",\n",
    ")\n",
    "\n",
    "salida_2 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/orgullo_y_prejuicio_muy_corto.txt\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardar√° el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminar√° del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False,  # no mostrar actualizaciones de proceso al ejecutar el c√≥digo\n",
    "    symbolic_directory_path=\"/novelas/romance\",\n",
    "    file_name=\"Pride and Prejudice.txt\",\n",
    ")\n",
    "\n",
    "salida_3 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/moby_dick_muy_corto.txt\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardar√° el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminar√° del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False,  # no mostrar actualizaciones de proceso al ejecutar el c√≥digo\n",
    "    symbolic_directory_path=\"/novelas/aventura\",\n",
    "    file_name=\"Moby Dick.txt\",\n",
    ")\n",
    "\n",
    "salida_4 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/mujercitas_muy_corto.txt\",  # la ruta de archivo inicial en la que yace el archivo de entrada\n",
    "    local_save_directory=data_dir + \"output\",  # el directorio local en el que se guardar√° el archivo de salida\n",
    "    expire_time=60 * 30,  # data de este proceso se eliminar√° del sistema Krixik en 30 minutos\n",
    "    wait_for_process=True,  # espera que el proceso termine antes de devolver control del IDE al usuario\n",
    "    verbose=False,  # no mostrar actualizaciones de proceso al ejecutar el c√≥digo\n",
    "    symbolic_directory_path=\"/novelas/bildungsroman\",\n",
    "    file_name=\"Little Women.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examina la salida de uno de estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"keyword_search_method_1_keyword-db\",\n",
      "  \"request_id\": \"4763d881-46e0-4d34-857b-bdd4cdf43aab\",\n",
      "  \"file_id\": \"ae071414-7192-4f78-a431-1a13c0f0bc4a\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id ae071414-7192-4f78-a431-1a13c0f0bc4a.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/ae071414-7192-4f78-a431-1a13c0f0bc4a.db\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# n√≠tidamente reproduce la salida de este proceso\n",
    "print(json.dumps(salida_3, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que la salida de este modelo/m√≥dulo es un archivo de base de datos `SQLlite`, `process_output` se muestra como \"null\". Esa base de datos consiste de todas las tuplas de palabras claves (palabra clave, n√∫mero de l√≠nea, n√∫mero de palabra) identificadas en el archivo, as√≠ que no se puede reproducir aqu√≠. Sin embargo, el archivo de salida se ha guardado en la ubicaci√≥n indicada bajo `process_output_files`. El `file_id` del archivo procesado es el prefijo del nombre del archivo de salida en esta ubicaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de Busquedas por Palabras Clave\n",
    "\n",
    "Ahora que has procesado archivos por el *pipeline* puedes usar el m√©todo `keyword_search` sobre √©l.\n",
    "\n",
    "Con el siguiente c√≥digo puedes buscar una serie de palabras en uno de los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"5b252162-6ee5-4a48-ae62-f9954f4107f5\",\n",
      "  \"message\": \"\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following file_ids returned no results for the given query\": [\n",
      "        \"001dd7c5-87f6-4ffa-a647-060291d9679d\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# haz keyword_search sobre un archivo\n",
    "keyword_output = pipeline.keyword_search(query=\"mansion adolescence party enemy romance\", file_names=[\"Little Women.txt\"])\n",
    "\n",
    "# n√≠tidamente reproduce la salida de este proceso\n",
    "print(json.dumps(keyword_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El m√©todo `keyword_search` devuelve cada aparici√≥n de cada palabra clave buscada. Como puedes ver, para cada archivo sobre el que buscaste hay un registro para cada aparici√≥n de palabra clave. El registro indica el n√∫mero de l√≠nea y el n√∫mero de palabra dentro de esa l√≠nea.\n",
    "\n",
    "Funciona igual de bien cuando buscas sobre varios archivos con el [operador comod√≠n](../sistema_de_archivos/metodo_list_lista.md#argumentos-con-el-operador-comodin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"5e53f349-ed65-4735-a288-d2effbb447a5\",\n",
      "  \"message\": \"Successfully queried the first 1 user file out of 4 defined by input query arguments.\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following file_ids returned no results for the given query\": [\n",
      "        \"ae071414-7192-4f78-a431-1a13c0f0bc4a\",\n",
      "        \"f59be5e9-2bd3-4a07-8a7e-1a52064c6ee1\",\n",
      "        \"001dd7c5-87f6-4ffa-a647-060291d9679d\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"786baed5-66ff-4bf4-941f-0baa562e9666\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 40,\n",
      "        \"created_at\": \"2024-06-05 16:18:15\",\n",
      "        \"last_updated\": \"2024-06-05 16:18:15\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"keyword\": \"party\",\n",
      "          \"line_number\": 23,\n",
      "          \"keyword_number\": 8\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# hacer keyword_search sobre varios archivos\n",
    "keyword_output = pipeline.keyword_search(query=\"mansion adolescence party enemy romance\", symbolic_directory_paths=[\"/novelas*\"])\n",
    "\n",
    "# n√≠tidamente reproduce la salida de este proceso\n",
    "print(json.dumps(keyword_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limite de Tamano de Salidas\n",
    "\n",
    "El l√≠mite actual sobre salidas generadas por el m√©todo `list` es 5MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words (Palabras Ignoradas)\n",
    "\n",
    "\"Stop words\", o \"palabras ignoradas\", son las palabras que la b√∫squeda por palabras clave ignora. Hay palabras en los idiomas que son tan comunes y frecuentemente usadas (p.ej. en ingl√©s \"the\" y \"and\") que asumimos que el usuario no las buscar√°. Por ende, el m√©todo `keyword_search` se las salta si est√°n en la consulta (*the query*), lo cual produce resultados m√°s enfocados. Por ahora no hay manera de hacer b√∫squeda por palabras clave por cualquier palabra en la lista de \"stop words\", lista que puedes ver en la salida del siguiente c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir + \"other/stop_words.txt\", \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# elimina todos los datos procesados pertenecientes a este pipeline\n",
    "krixik.reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
