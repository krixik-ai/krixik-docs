{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/system/parameters_processing_files_through_pipelines/process_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# demo setup - including secrets instantiation, requirements installation, and path setting\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # if running this notebook in Google Colab - make sure to enter your secrets\n",
    "    MY_API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "    MY_API_URL = \"YOUR_API_URL_HERE\"\n",
    "\n",
    "    # if running this notebook on Google Colab - install requirements and pull required subdirectories\n",
    "    # install Krixik python client\n",
    "    !pip install krixik\n",
    "\n",
    "    # install github clone - allows for easy cloning of subdirectories from docs repo: https://github.com/krixik-ai/krixik-docs\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clone datasets\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/main/data\n",
    "    else:\n",
    "        print(\"docs datasets already cloned!\")\n",
    "\n",
    "    # define data dir\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # create output dir\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # pull utilities\n",
    "    if not Path(\"utilities\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/main/utilities\n",
    "    else:\n",
    "        print(\"docs utilities already cloned!\")\n",
    "else:\n",
    "    # if running local pull of docs - set paths relative to local docs structure\n",
    "    # import utilities\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define data_dir\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # if running this notebook locally from Krixik docs repo - load secrets from a .env placed at the base of the docs repo\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "\n",
    "# load in reset\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "\n",
    "# import Krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Parameterizable `process` Method\n",
    "\n",
    "The `process` method, available on every Krixik pipeline, is invoked whenever you wish to process files through a pipeline.\n",
    "\n",
    "This overview of the `process` method is divided into the following sections:\n",
    "\n",
    "- [Core process Method Arguments](#core-process-method-arguments)\n",
    "- [Basic Usage and Output Breakdown](#basic-usage-and-output-breakdown)\n",
    "- [Selecting Models Via the modules Argument](#selecting-models-via-the-modules-argument)\n",
    "- [Using your own Models](#using-your-own-models)\n",
    "- [Optional Metadata Arguments](#optional-metadata-arguments)\n",
    "- [Metadata Argument Defaults](#metadata-argument-defaults)\n",
    "- [Automatic File Type Conversions](#automatic-file-type-conversions)\n",
    "- [Output Size Cap](#output-size-cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core `process` Method Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process` method takes five basic arguments (in addition to the `modules` argument and a series of optional metadata arguments, all discussed further below). These five arguments are:\n",
    "\n",
    "- `local_file_path`: (required, str) The local file path of the file you wish to process through the pipeline.\n",
    "\n",
    "- `local_save_directory`: (optional, str) The local directory you want process output saved to. Defaults to the current working directory.\n",
    "\n",
    "- `expire_time`: (optional, int) The amount of time (in seconds) that process output remains on Krixik servers. Defaults to 1800 seconds, which is 30 minutes.\n",
    "\n",
    "- `wait_for_process`: (optional, bool) Indicates whether or not Krixik should wait for your process to complete before returning control of your IDE or notebook. `True` tells Krixik to wait until the process is complete, so you won't be able to execute anything else in the meantime. `False` tells Krixik that you wish to regain control as soon as file upload to the Krixik system has concluded.  When set to `False`, processing status can be examined via the [`process_status`](process_status_method.md) method. Defaults to `True`.\n",
    "\n",
    "- `verbose`: (optional, bool) Determines if Krixik should immediately display process update printouts at your terminal/notebook. Defaults to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage and Output Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a single-module pipeline to demonstrate the `process` method with. We'll use a [`sentiment`](../../modules/ai_modules/sentiment_module.md) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single-module pipeline for process demo\n",
    "pipeline = krixik.create_pipeline(name=\"process_method_1_sentiment\", module_chain=[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've locally created a JSON file that holds three snippets that simulate online product reviews. The snippets read as follows:\n",
    "\n",
    "- This recliner is the best damn seat I've ever come across. When I fall asleep on it, which is often, I sleep like a baby.\n",
    "\n",
    "- This recliner is terrible. It broke on its way out of the box, and no matter what I try, it doesn't recline. Avoid at all costs.\n",
    "\n",
    "- I've sat on a lot of recliners in my life. I've forgotten about most of them. I'll forget about this one as well.\n",
    "\n",
    "Keep in mind that input JSON files _must_ follow a very [specific format](JSON_input_format.md). If they don't, they'll be rejected by Krixik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process short input file\n",
    "process_demo_output = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/recliner_reviews.json\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=data_dir + \"output\",  # the local directory that the output file will be saved to\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 10 minutes\n",
    "    wait_for_process=True,  # wait for process to complete before returning IDE control to user\n",
    "    verbose=False,\n",
    ")  # do not display process update printouts upon running code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the output of the process.  Because the output of this particular module-model pair is in JSON format, we can print it nicely with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"process_method_1_sentiment\",\n",
      "  \"request_id\": \"339ef4dd-5c97-4822-b450-aea700bc6021\",\n",
      "  \"file_id\": \"6a314cdb-6938-4663-aef5-a0258341c120\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 6a314cdb-6938-4663-aef5-a0258341c120.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"This recliner is the best damn seat I've ever come across. When I fall asleep on it, which is often, I sleep like a baby.\",\n",
      "      \"positive\": 0.871,\n",
      "      \"negative\": 0.129,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"This recliner is terrible. It broke on its way out of the box, and no matter what I try, it doesn't recline. Avoid at all costs.\",\n",
      "      \"positive\": 0.001,\n",
      "      \"negative\": 0.999,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"I've sat on a lot of recliners in my life. I've forgotten about most of them. I'll forget about this one as well.\",\n",
      "      \"positive\": 0.001,\n",
      "      \"negative\": 0.999,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/6a314cdb-6938-4663-aef5-a0258341c120.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of the above process\n",
    "import json\n",
    "\n",
    "print(json.dumps(process_demo_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the output:\n",
    "\n",
    "- `status_code`: The HTTP status code for this process (e.g. \"200\", \"500\")\n",
    "\n",
    "- `pipeline`: The `name` of the pipeline we just ran `process` on.\n",
    "\n",
    "- `request_id`: The unique ID associated with this execution of `process`.\n",
    "\n",
    "- `file_id`: The unique server-side ID for the now-processed file (and thus its associated output).\n",
    "\n",
    "- `message`: This message specifies SUCCESS or FAILURE for the method call and offers detail.\n",
    "\n",
    "- `warnings`: A message list that includes any warnings related to the method call.\n",
    "\n",
    "- `process_output`: The output of the process. In this case, since the output is in JSON format, it's easily printable in a code notebook.\n",
    "\n",
    "- `process_output_files`: A list of file names and file paths generated as process outputs and saved locally.\n",
    "\n",
    "\n",
    "We can see from `process_output` that our [`sentiment analysis`](../../modules/ai_modules/sentiment_module.md) pipeline has worked correctly. Each of the product reviews has been assigned a sentiment value breakdown between positive, negative, and neutral.\n",
    "\n",
    "In addition to being printed here, this process output is also stored in the file indicated in `process_output_files`. Let's load it in and confirm that it shows the same process output we received above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"This recliner is the best damn seat I've ever come across. When I fall asleep on it, which is often, I sleep like a baby.\",\n",
      "    \"positive\": 0.871,\n",
      "    \"negative\": 0.129,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"This recliner is terrible. It broke on its way out of the box, and no matter what I try, it doesn't recline. Avoid at all costs.\",\n",
      "    \"positive\": 0.001,\n",
      "    \"negative\": 0.999,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"I've sat on a lot of recliners in my life. I've forgotten about most of them. I'll forget about this one as well.\",\n",
      "    \"positive\": 0.001,\n",
      "    \"negative\": 0.999,\n",
      "    \"neutral\": 0.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "import json\n",
    "\n",
    "with open(process_demo_output[\"process_output_files\"][0], \"r\") as file:\n",
    "    print(json.dumps(json.load(file), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Models Via the `modules` Argument\n",
    "\n",
    "The `modules` argument to the `process` method is optional, but through it you can access a wealth of parameterization options. This argument allows you to parameterize how each module operates, **INCLUDING** the determination of (when applicable) what AI model is active within it.\n",
    "\n",
    "The `modules` argument takes the form of a dictionary with dictionaries within it. On a single-module pipeline it looks like this:\n",
    "\n",
    "```python\n",
    "modules={'<model name>': {'model':'<model selection>', 'params': <dictionary of parameters>}}\n",
    "```\n",
    "\n",
    "Bear in mind that model names are case sensitive.\n",
    "\n",
    "An example for a single-module pipeline that holds a [`caption`](../../modules/ai_modules/caption_module.md) module would specifically look like this, `blip-image-captioning-base` being the available model selected:\n",
    "\n",
    "```python\n",
    "modules={'caption': {'model':'blip-image-captioning-base', 'params': {}}}\n",
    "```\n",
    "\n",
    "In the above example `params` is an empty dictionary because [`caption`](../../modules/ai_modules/caption_module.md) module models don't take any parameters. Other types of models do, such as the [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) module models. This is what the `modules` argument might look like for a single-module [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) pipeline:\n",
    "\n",
    "modules={'text-embedder': {'model':'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': False}}}\n",
    "\n",
    "`quantize` is a parameter that you can set for [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) module models, and only for [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) module models.\n",
    "\n",
    "The `modules` argument syntax for multi-module pipelines is similar to the above, but in that case there's one sub-dictionary for every module. For instance, the `modules` argument for a [vector search pipeline](../../examples/search_pipeline_examples/multi_basic_semantic_search.md) that sequentially chains together [`parser`](../../modules/support_function_modules/parser_module.md), [`text-embedder`](../../modules/ai_modules/text-embedder_module.md), and [`vector-db`](../../modules/database_modules/vector-db_module.md) modules might look like this:\n",
    "\n",
    "```python\n",
    "modules={'parser': {'model':'fixed', 'params': {\"chunk_size\": 10, \"overlap_size\": 5}},\n",
    "         'text-embedder': {'model':'all-MiniLM-L6-v2', 'params': {}},\n",
    "         'vector-db': {'model':'faiss', 'params': {}}}\n",
    "```\n",
    "\n",
    "Note that any modules not explicitly called out will take their default values. If you need to specify one module's model or its params, that doesn't mean you need to specify all of them in the pipeline. Consequently, given that in the code immediately above the [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) and [`vector-db`](../../modules/database_modules/vector-db_module.md) modules above are being set to their default values, you could achieve the exact same thing by removing them from the code and only leaving the [`parser`](../../modules/support_function_modules/parser_module.md) module, as follows:\n",
    "\n",
    "```python\n",
    "modules={'parser': {'model':'fixed', 'params': {\"chunk_size\": 10, \"overlap_size\": 5}}}\n",
    "```\n",
    "\n",
    "Find detail on each of our current modules, including available models for each, [here](../../modules/modules_overview.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your own Models\n",
    "\n",
    "Do you have a model—either one you've developed or one you've fine-tuned—that you'd like to use on Krixik?\n",
    "\n",
    "Please [click here](../../modules/adding_your_own_modules_or_models.md) to learn how to do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Metadata Arguments\n",
    "\n",
    "The `process` method also takes a variety of optional metadata arguments. These do not change how `process` runs or treats data. Instead, they make your processed files easier to retrieve and organize. You can think of it as a file system for files you've processed through your pipelines.\n",
    "\n",
    "Optional metadata arguments include:\n",
    "\n",
    "- `symbolic_directory_path` (str) - A UNIX-formatted directory path under your account in the Krixik system. Default is `/etc`.\n",
    "\n",
    "- `file_name` (str) - A custom file name that must end with the file extension of the original input file. Default is a randomly-generated string (see below).\n",
    "\n",
    "- `symbolic_file_path` (str) - A combination of `symbolic_directory_path` and `file_name` in a single argument. Default is a concatenation of the default of each.\n",
    "\n",
    "- `file_tags` (list) - A list of custom file tags (each a key-value pair). Default is an empty list.\n",
    "\n",
    "- `file_description` (str) - A custom file description. Default is an empty string.\n",
    "\n",
    "The first four of these—`symbolic_directory_path`, `file_name`, `symbolic_directory_path`, and `file_tags`—can be used as arguments to the [`list`](../file_system/list_method.md) method and to the [`keyword_search`](../search_methods/keyword_search_method.md) and [`semantic_search`](../search_methods/semantic_search_method.md) methods.\n",
    "\n",
    "Note that a file you process through one pipeline is only accessible to that pipeline. If you upload a file to a certain `symbolic_directory_path` on a certain pipeline, for instance, you will not be able to [`list`](../file_system/list_method.md), [search](../../examples/search_pipeline_examples/search_pipelines_overview.md), or otherwise access it from any other pipeline, even if you target the same `symbolic_directory_path` from there.\n",
    "\n",
    "Also note that a `symbolic_file_path` cannot be duplicated within a pipeline. In other words, if on a certain pipeline you `process` a file to a specified `symbolic_directory_path` and `file_name`, Krixik will not allow you to `process` any other files with that same combination of `symbolic_file_path` and `file_name`.\n",
    "\n",
    "Let's call the `process` method once more. We'll use the same product review file as before, but expand our line of code with some of these optional metadata arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process short input file with optional metadata arguments\n",
    "process_demo_output = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/recliner_reviews.json\",\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,\n",
    "    wait_for_process=True,\n",
    "    verbose=False,\n",
    "    symbolic_directory_path=\"/my/custom/filepath\",\n",
    "    file_name=\"product_reviews.json\",\n",
    "    file_tags=[{\"category\": \"furniture\"}, {\"product code\": \"recliner-47b-u11\"}],\n",
    "    file_description=\"Three product reviews for the Orwell Cloq recliner.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Argument Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If no `file_name` is provided, a random one is generated. It takes the form `krixik_generated_file_name_{10 random chars}.ext`, where here `.ext` is the extension of your input file provided in `local_file_path`.\n",
    "\n",
    "- If no `symbolic_directory_path` is provided, the default value it takes is `/etc`.\n",
    "\n",
    "- Note that you cannot define any children directories under the `symbolic_directory_path` `/etc`; it is the catch-all directory, and is not meant to be built under."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic File Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain modules, the `process` method automatically converts the format of some `local_file_path` input files. Conversions currently done by Krixik are:\n",
    "\n",
    "- `pdf` -> `txt`\n",
    "- `docx` -> `txt`\n",
    "- `pptx` -> `txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Size Cap\n",
    "\n",
    "The current size limit on output generated by the `process` method is 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
