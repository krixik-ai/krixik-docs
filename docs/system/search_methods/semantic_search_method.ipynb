{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/krixik-ai/krixik-docs/blob/main/docs/system/search_methods/semantic_search_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# demo setup - including secrets instantiation, requirements installation, and path setting\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # if running this notebook in collab - make sure to enter your secrets\n",
    "    MY_API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "    MY_API_URL = \"YOUR_API_URL_HERE\"\n",
    "\n",
    "    # if running this notebook on collab - install requirements and pull required subdirectories\n",
    "    # install krixik python client\n",
    "    !pip install krixik\n",
    "\n",
    "    # install github clone - allows for easy cloning of subdirectories from docs repo: https://github.com/krixik-ai/krixik-docs\n",
    "    !pip install github-clone\n",
    "\n",
    "    # clone datasets\n",
    "    if not Path(\"data\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/main/data\n",
    "    else:\n",
    "        print(\"docs datasets already cloned!\")\n",
    "\n",
    "    # define data dir\n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    # create output dir\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(data_dir + \"/output\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # pull utilities\n",
    "    if not Path(\"utilities\").is_dir():\n",
    "        !ghclone https://github.com/krixik-ai/krixik-docs/tree/main/utilities\n",
    "    else:\n",
    "        print(\"docs utilities already cloned!\")\n",
    "else:\n",
    "    # if running local pull of docs - set paths relative to local docs structure\n",
    "    # import utilities\n",
    "    sys.path.append(\"../../../\")\n",
    "\n",
    "    # define data_dir\n",
    "    data_dir = \"../../../data/\"\n",
    "\n",
    "    # if running this notebook locally from krixik docs repo - load secrets from a .env placed at the base of the docs repo\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(\"../../../.env\")\n",
    "\n",
    "    MY_API_KEY = os.getenv(\"MY_API_KEY\")\n",
    "    MY_API_URL = os.getenv(\"MY_API_URL\")\n",
    "\n",
    "\n",
    "# load in reset\n",
    "reset = importlib.import_module(\"utilities.reset\")\n",
    "reset_pipeline = reset.reset_pipeline\n",
    "\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "\n",
    "krixik.init(api_key=MY_API_KEY, api_url=MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `semantic_search` Method\n",
    "\n",
    "Krixik's `semantic_search` method enables semantic search on documents processed through certain pipelines. Much has been written about semantic search, but in a nutshell, instead of searching a document for specific keywords, it searches for text similar in _meaning_ to the string that's been queried for. Contrast this to [keyword search](keyword_search_method.md).\n",
    "\n",
    "Given that the `semantic_search` method both [embeds](../../modules/ai_modules/text-embedder_module.md) the query and performs the search, it can only be used with pipelines containing both a [`text-embedder`](../../modules/ai_modules/text-embedder_module.md) module and a [`vector-db`](../../modules/database_modules/vector-db_module.md) module in immediate succession.\n",
    "\n",
    "This overview of the `semantic_search` method is divided into the following sections:\n",
    "\n",
    "- [semantic_search Method Arguments](#semantic_search-method-arguments)\n",
    "- [Example Pipeline Setup and File Processing](#example-pipeline-setup-and-file-processing)\n",
    "- [Example Semantic Searches](#example-semantic-searches)\n",
    "- [Output Size Cap](#output-size-cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `semantic_search` Method Arguments\n",
    "\n",
    "The `semantic_search` method takes one required argument and at least one of several optional arguments. The required argument is:\n",
    "\n",
    "- `query` (str) - A string whose meaning will be searched for across the target document. The closest matches (i.e. snippets of text that most match the query in meaning) will be returned.\n",
    "\n",
    "The optional arguments are the same arguments that the [`list`](../file_system/list_method.md) method takes—both metadata and timestamp bookends—so please take a moment to [review them here](../file_system/list_method.md#list-method-arguments). As with the [`list`](../file_system/list_method.md) method, you can semantically search across several files at the same time because all metadata arguments are submitted to the `semantic_search` method in list format. All optional argument elements are the same as for the [`list`](../file_system/list_method.md) method, including the wildcard operator and the global root.\n",
    "\n",
    "If none of these optional arguments is present, the `semantic_search` method will not work because there will be nothing to search through.\n",
    "\n",
    "Like the [`list`](../file_system/list_method.md) method, the `semantic_search` method also accepts the optional `max_files` and `sort_order` arguments, though their function changes a bit:\n",
    "\n",
    "- `max_files` - Specifies up to how many files should be searched through. Default is none.\n",
    "\n",
    "- `sort_order` - Here takes three possible values: 'ascending', descending', and now 'global'. The first two sort results by the file they're in (the files are sorted by the creation timestamp of the file), and 'global' combines all files and returns the very best results across all files. Default is 'descending'.\n",
    "\n",
    "Finally, the `semantic_search` method accepts one optional method that is unique to it:\n",
    "\n",
    "- `k` (int) - Specifies up to how many results will be returned per queried file. Default is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Pipeline Setup and File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this document's examples we will use a pipeline consisting of three modules: a [`parser module`](../../modules/support_function_modules/parser_module.md), a [`text-embedder module`](../../modules/ai_modules/text-embedder_module.md), and a [`vector-db module`](../../modules/database_modules/vector-db_module.md). This is the basic semantic search [pipeline](../../examples/search_pipeline_examples/multi_basic_semantic_search.md). We use the [`create_pipeline`](../pipeline_creation/create_pipeline.md) method to instantiate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the basic semantic search pipeline\n",
    "pipeline = krixik.create_pipeline(\n",
    "    name=\"semantic_search_method_1_parser_text-embedder_vector-db\", module_chain=[\"parser\", \"text-embedder\", \"vector-db\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline ready, we'll [`process`](../parameters_processing_files_through_pipelines/process_method.md) a few text files through it so we have something to search through. Let's use the same files we used in the [`list` method documentation](../file_system/list_method.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add four files to the pipeline we just created.\n",
    "output_1 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/frankenstein_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/gothic\",\n",
    "    file_name=\"Frankenstein.txt\",\n",
    ")\n",
    "\n",
    "output_2 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/pride_and_prejudice_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/romance\",\n",
    "    file_name=\"Pride and Prejudice.txt\",\n",
    ")\n",
    "\n",
    "output_3 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/moby_dick_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/adventure\",\n",
    "    file_name=\"Moby Dick.txt\",\n",
    ")\n",
    "\n",
    "output_4 = pipeline.process(\n",
    "    local_file_path=data_dir + \"input/little_women_very_short.txt\",  # the initial local filepath where the input JSON file is stored\n",
    "    local_save_directory=data_dir + \"output\",\n",
    "    expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "    wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "    verbose=False,  # do not display process update printouts upon running code\n",
    "    symbolic_directory_path=\"/novels/bildungsroman\",\n",
    "    file_name=\"Little Women.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output for one of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"semantic_search_method_1_parser_text-embedder_vector-db\",\n",
      "  \"request_id\": \"4197e750-0560-43b9-b7e3-0ea5c8f15151\",\n",
      "  \"file_id\": \"a94765c2-0250-4b3d-98af-20fc167640e8\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id a94765c2-0250-4b3d-98af-20fc167640e8.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"../../../data/output/a94765c2-0250-4b3d-98af-20fc167640e8.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of one of the above processes\n",
    "print(json.dumps(output_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `process_output` is `null` because the return object is a database, so it cannot be printed here. You can review this database in the local location provided in the `process_output_files`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Semantic Searches\n",
    "\n",
    "With files now processed through the pipeline we can run the `semantic_search` method on it.\n",
    "\n",
    "Let's try an example in which we query one of the files file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"c1b9116f-0eaa-489d-a8f4-86ca7238e744\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"853f498f-4b1c-439b-bbd4-ccc47c44d254\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 43,\n",
      "        \"created_at\": \"2024-06-05 16:19:43\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:43\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"The four young faces on which the firelight shone brightened at the\\ncheerful words, but darkened again as Jo said sadly,--\\n\\n\\\"We haven't got father, and shall not have him for a long time.\\\"\",\n",
      "          \"line_numbers\": [\n",
      "            19,\n",
      "            20,\n",
      "            21,\n",
      "            22,\n",
      "            23\n",
      "          ],\n",
      "          \"distance\": 0.351\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Nobody spoke for a minute; then Meg said in an altered tone,--\\n\\n\\\"You know the reason mother proposed not having any presents this\\nChristmas was because it is going to be a hard winter for every one; and\\nshe thinks we ought not to spend money for pleasure, when our men are\\nsuffering so in the army.\",\n",
      "          \"line_numbers\": [\n",
      "            26,\n",
      "            27,\n",
      "            28,\n",
      "            29,\n",
      "            30,\n",
      "            31,\n",
      "            32\n",
      "          ],\n",
      "          \"distance\": 0.363\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"said Meg, who could remember better times.\",\n",
      "          \"line_numbers\": [\n",
      "            82\n",
      "          ],\n",
      "          \"distance\": 0.402\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"\\\"It's so dreadful to be poor!\\\"\",\n",
      "          \"line_numbers\": [\n",
      "            9,\n",
      "            10\n",
      "          ],\n",
      "          \"distance\": 0.402\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"\\\"How would you\\nlike to be shut up for hours with a nervous, fussy old lady, who keeps\\nyou trotting, is never satisfied, and worries you till you're ready to\\nfly out of the window or cry?\\\"\",\n",
      "          \"line_numbers\": [\n",
      "            58,\n",
      "            59,\n",
      "            60,\n",
      "            61\n",
      "          ],\n",
      "          \"distance\": 0.403\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over one file\n",
    "semantic_output = pipeline.semantic_search(query=\"It was cold night.\", file_names=[\"Little Women.txt\"])\n",
    "\n",
    "# nicely print the output of this search\n",
    "print(json.dumps(semantic_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to returning the snippets that are closest in meaning to our query, we also see the calculated vector distance (in a way, the distance in meaning) between each result and the query. The shorter this distance is, the closer in meaning the result to the query. The `semantic_search` method returns the snippets with the shortest vector distance to query, ranked in ascending order within each file.\n",
    "\n",
    "When `sort_order` is set to 'global', results from all files are combined and the method returns the snippets with the shortest distance to query, ranked in ascending order, regardless of what file each result may be in. Let's give this a shot by searching through multiple files with the [wildcard operator](../file_system/list_method.md#wildcard-operator-arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"ba1b7b85-8e36-49e5-8734-68c80d19e433\",\n",
      "  \"message\": \"Successfully queried 4 user files.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"snippet\": \"I am already far north of London, and as I walk in the streets of\\nPetersburgh, I feel a cold northern breeze play upon my cheeks, which\\nbraces my nerves and fills me with delight.\",\n",
      "      \"distance\": 0.33,\n",
      "      \"line_numbers\": [\n",
      "        14,\n",
      "        15,\n",
      "        16,\n",
      "        17\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"f4720361-f94f-4f48-a4bf-0177dd91ba18\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:17:58\",\n",
      "        \"last_updated\": \"2024-06-05 16:17:58\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"This breeze, which has travelled from the regions towards\\nwhich I am advancing, gives me a foretaste of those icy climes.\",\n",
      "      \"distance\": 0.336,\n",
      "      \"line_numbers\": [\n",
      "        18,\n",
      "        19\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"f4720361-f94f-4f48-a4bf-0177dd91ba18\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:17:58\",\n",
      "        \"last_updated\": \"2024-06-05 16:17:58\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"The four young faces on which the firelight shone brightened at the\\ncheerful words, but darkened again as Jo said sadly,--\\n\\n\\\"We haven't got father, and shall not have him for a long time.\\\"\",\n",
      "      \"distance\": 0.351,\n",
      "      \"line_numbers\": [\n",
      "        19,\n",
      "        20,\n",
      "        21,\n",
      "        22,\n",
      "        23\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"853f498f-4b1c-439b-bbd4-ccc47c44d254\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:43\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:43\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"There\\u2014for with your leave, my sister, I will put\\nsome trust in preceding navigators\\u2014there snow and frost are banished;\\nand, sailing over a calm sea, we may be wafted to a land surpassing in\\nwonders and in beauty every region hitherto discovered on the habitable\\nglobe.\",\n",
      "      \"distance\": 0.362,\n",
      "      \"line_numbers\": [\n",
      "        25,\n",
      "        26,\n",
      "        27,\n",
      "        28,\n",
      "        29\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"f4720361-f94f-4f48-a4bf-0177dd91ba18\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:17:58\",\n",
      "        \"last_updated\": \"2024-06-05 16:17:58\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Nobody spoke for a minute; then Meg said in an altered tone,--\\n\\n\\\"You know the reason mother proposed not having any presents this\\nChristmas was because it is going to be a hard winter for every one; and\\nshe thinks we ought not to spend money for pleasure, when our men are\\nsuffering so in the army.\",\n",
      "      \"distance\": 0.363,\n",
      "      \"line_numbers\": [\n",
      "        26,\n",
      "        27,\n",
      "        28,\n",
      "        29,\n",
      "        30,\n",
      "        31,\n",
      "        32\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"853f498f-4b1c-439b-bbd4-ccc47c44d254\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:43\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:43\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"There, Margaret, the sun is for ever\\nvisible, its broad disk just skirting the horizon and diffusing a\\nperpetual splendour.\",\n",
      "      \"distance\": 0.377,\n",
      "      \"line_numbers\": [\n",
      "        23,\n",
      "        24,\n",
      "        25\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"f4720361-f94f-4f48-a4bf-0177dd91ba18\",\n",
      "        \"file_name\": \"frankenstein.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/gothic\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:17:58\",\n",
      "        \"last_updated\": \"2024-06-05 16:17:58\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Far from it.\",\n",
      "      \"distance\": 0.389,\n",
      "      \"line_numbers\": [\n",
      "        11\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"d9e477d5-9b2c-4bf3-aa25-b6c739b83b86\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:31\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:31\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"said Meg, who could remember better times.\",\n",
      "      \"distance\": 0.402,\n",
      "      \"line_numbers\": [\n",
      "        82\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"853f498f-4b1c-439b-bbd4-ccc47c44d254\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:43\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:43\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"\\\"It's so dreadful to be poor!\\\"\",\n",
      "      \"distance\": 0.402,\n",
      "      \"line_numbers\": [\n",
      "        9,\n",
      "        10\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"853f498f-4b1c-439b-bbd4-ccc47c44d254\",\n",
      "        \"file_name\": \"little women.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/bildungsroman\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:43\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:43\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"But gulp down your tears and hie aloft to the\\n  royal-mast with your hearts; for your friends who have gone before\\n  are clearing out the seven-storied heavens, and making refugees of\\n  long-pampered Gabriel, Michael, and Raphael, against your coming.\",\n",
      "      \"distance\": 0.41,\n",
      "      \"line_numbers\": [\n",
      "        27,\n",
      "        28,\n",
      "        29,\n",
      "        30\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"d9e477d5-9b2c-4bf3-aa25-b6c739b83b86\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:31\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:31\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"It will be seen that this mere painstaking burrower and grub-worm of\\n  a poor devil of a Sub-Sub appears to have gone through the long\\n  Vaticans and street-stalls of the earth, picking up whatever random\\n  allusions to whales he could anyways find in any book whatsoever,\\n  sacred or profane.\",\n",
      "      \"distance\": 0.433,\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5,\n",
      "        6,\n",
      "        7,\n",
      "        8,\n",
      "        9\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"d9e477d5-9b2c-4bf3-aa25-b6c739b83b86\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:31\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:31\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Would that I could clear out Hampton Court and the\\n  Tuileries for ye!\",\n",
      "      \"distance\": 0.438,\n",
      "      \"line_numbers\": [\n",
      "        26,\n",
      "        27\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"d9e477d5-9b2c-4bf3-aa25-b6c739b83b86\",\n",
      "        \"file_name\": \"moby dick.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/adventure\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:31\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:31\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"On the other hand,\\nI, for my part, declare for_ Pride and Prejudice _unhesitatingly.\",\n",
      "      \"distance\": 0.438,\n",
      "      \"line_numbers\": [\n",
      "        35,\n",
      "        36\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"a94765c2-0250-4b3d-98af-20fc167640e8\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:18\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:18\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"The catastrophe of_ Mansfield Park _is admittedly\\ntheatrical, the hero and heroine are insipid, and the author has almost\\nwickedly destroyed all romantic interest by expressly admitting that\\nEdmund only took Fanny because Mary shocked him, and that Fanny might\\nvery likely have taken Crawford if he had been a little more assiduous;\\nyet the matchless rehearsal-scenes and the characters of Mrs. Norris and\\nothers have secured, I believe, a considerable party for it._ Sense and\\nSensibility _has perhaps the fewest out-and-out admirers; but it dos\\nnot want them._\\n\\n_I suppose, however, that the majority of at least competent votes\\nwould, all things considered, be divided between_ Emma _and the present\\nbook; and perhaps the vulgar verdict (if indeed a fondness for Miss\\nAusten be not of itself a patent of exemption from any possible charge\\nof vulgarity) would go for_ Emma.\",\n",
      "      \"distance\": 0.465,\n",
      "      \"line_numbers\": [\n",
      "        17,\n",
      "        18,\n",
      "        19,\n",
      "        20,\n",
      "        21,\n",
      "        22,\n",
      "        23,\n",
      "        24,\n",
      "        25,\n",
      "        26,\n",
      "        27,\n",
      "        28,\n",
      "        29,\n",
      "        30,\n",
      "        31\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"a94765c2-0250-4b3d-98af-20fc167640e8\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:18\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:18\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To some the delightful freshness and humour of_ Northanger\\nAbbey, _its completeness, finish, and_ entrain, _obscure the undoubted\\ncritical facts that its scale is small, and its scheme, after all, that\\nof burlesque or parody, a kind in which the first rank is reached with\\ndifficulty._ Persuasion, _relatively faint in tone, and not enthralling\\nin interest, has devotees who exalt above all the others its exquisite\\ndelicacy and keeping.\",\n",
      "      \"distance\": 0.468,\n",
      "      \"line_numbers\": [\n",
      "        11,\n",
      "        12,\n",
      "        13,\n",
      "        14,\n",
      "        15,\n",
      "        16,\n",
      "        17\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"a94765c2-0250-4b3d-98af-20fc167640e8\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:18\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:18\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"And in the sect--fairly large and yet\\nunusually choice--of Austenians or Janites, there would probably be\\nfound partisans of the claim to primacy of almost every one of the\\nnovels.\",\n",
      "      \"distance\": 0.479,\n",
      "      \"line_numbers\": [\n",
      "        8,\n",
      "        9,\n",
      "        10,\n",
      "        11\n",
      "      ],\n",
      "      \"file_metadata\": {\n",
      "        \"file_id\": \"a94765c2-0250-4b3d-98af-20fc167640e8\",\n",
      "        \"file_name\": \"pride and prejudice.txt\",\n",
      "        \"symbolic_directory_path\": \"/novels/romance\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 0,\n",
      "        \"created_at\": \"2024-06-05 16:19:18\",\n",
      "        \"last_updated\": \"2024-06-05 16:19:18\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform semantic_search over multiple files\n",
    "semantic_output = pipeline.semantic_search(query=\"It was cold night.\", symbolic_directory_paths=[\"/novels*\"], sort_order=\"global\", k=4)\n",
    "\n",
    "# nicely print the output of this search\n",
    "print(json.dumps(semantic_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, results from all the files have been combined, and the result ranked at the top has the shortest query-result distance of the entire file set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Size Cap\n",
    "\n",
    "The current size limit on output generated by the `semantic_search` method is 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
