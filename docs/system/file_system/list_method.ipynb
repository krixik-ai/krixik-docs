{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `.list` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the [`process`](../parameters_processing_files_through_pipelines/process_method.md) method to process one or several files through your chosen pipeline, you can retrieve the record of any file(s) with the `.list` method. You can `.list` by `file_id` or by any other metadata you included when initially processing the file.  \n",
    "\n",
    "This overview of the `.list` method is divided into the following sections:\n",
    "\n",
    "- [.list Method Arguments](#.list-method-arguments)\n",
    "- [Example Pipeline Setup and File Processing](#example-pipeline-setup-and-file-processing)\n",
    "- [Listing by `file_ids`](#listing-by-file_ids)\n",
    "- [Listing by `file_names`](#listing-by-file_names)\n",
    "- [Listing by `symbolic_directory_paths`](#listing-by-symbolic_directory_paths)\n",
    "- [Listing by `file_tags`](#listing-by-file_tags)\n",
    "- [listing by `created_at` and `updated_at` Bookend Times](#listing-by-created_at-and-updated_at-bookend-times)\n",
    "- [Wildcard Operator * Arguments](#wildcard-operator-*-arguments)\n",
    "- [The Global Root](#the-global-root)\n",
    "- [Using Multiple Arguments with the `.list` Method](#using-multiple-arguments-with-the-.list-method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.list` Method Arguments\n",
    "\n",
    "The `.list` method is very versatile. It allows you to list by several different metadata items and by a combination of different metadata items.\n",
    "\n",
    "All of the following arguments are optional. However, you must use at least one argument for the `.list` method to function.\n",
    "\n",
    "For a refresher on file system metadata arguments please visit the [`process` method overview](../parameters_processing_files_through_pipelines/process_method.md). The metadata arguments you can use for `.list` are:\n",
    "\n",
    "- `file_ids`: A list of one or several `file_id`s to return records for.\n",
    "\n",
    "- `file_names`: A list of  one or several `file_name`s to return records for.\n",
    "\n",
    "- `symbolic_directory_paths`: A list of one or several `symbolic_directory_path`s to return records for.\n",
    "\n",
    "- `symbolic_file_paths`: A list of one or several `symbolic_file_path`s to return records for.\n",
    "\n",
    "- `file_tags`: A list of one or several `file_tag`s to return records for. Note that individual file_tags suffice; if a file has several file tags and you include at least one of them as a `.list` argument, that file's record will be returned.\n",
    "\n",
    "You may use wildcard operators with `file_names`, `symbolic_directory_paths`,`symbolic_file_paths`, and `file_tags` to retrieve records whose exact metadata you don't remember—or if you wish to retrieve records for a group of files that share similar metadata. More on wildcards operators [later](#wildcard-operator-*-arguments) in this document.\n",
    "\n",
    "You may also list by timestamp bookends. The `.list` method accepts timestamps based on both the creation and latest-update times of your records. These are strings in the `\"YYYY-MM-DD HH:MM:SS\"` format, or alternatively just in the `\"YYYY-MM-DD\"` format.\n",
    "\n",
    "- `created_at_start`: Filters out all files whose `created_at` time is earlier than what you've specified.\n",
    "\n",
    "- `created_at_end`: Filters out all files whose `created_at` time is after what you've specified.\n",
    "\n",
    "- `last_updated_start`: Filters out all files whose `last_updated` time is earlier than what you've specified.\n",
    "\n",
    "- `last_updated_end`: Filters out all files whose `last_updated` time is after what you've specified.\n",
    "\n",
    "Examples on how to use metadata and timestamps in the `.list` method are included below.\n",
    "\n",
    "Note that file system metadata arguments operate on **OR** logic: for instance, if you `.list` by `file_names`, `file_ids`, and `file_tags`, any file that is a match for any of these will be returned. However, timestamp arguments operate on **AND** logic; all files returned must respect the given timestamp bookends. If two timestamp bookends are given and there is no overlap between them, the `.list` method will return nothing.\n",
    "\n",
    "Finally, the `.list` method takes two additional optional arguments to help you organize your output:\n",
    "\n",
    "- `max_files` (int): Determines the maximum number of file records `.list` should return. Defaults to none.\n",
    "\n",
    "- `sort_order` (str): Specifies how results should be sorted. The two valid values for this argument are 'ascending' and 'descending' (in reference to creation timestamp). Defaults to 'descending'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Pipeline Setup and File Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to create a pipeline and [`.process`](../parameters_processing_files_through_pipelines/process_method.md) a couple of files through it to illustrate usage of `.list`. We'll create a single-module pipeline with a [`summarize`](../../modules/ai_model_modules/summarize_module.md) module and [`.process`](../parameters_processing_files_through_pipelines/process_method.md) some TXT files that hold the text of some English-language classics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single-module summarize pipeline\n",
    "\n",
    "pipeline_1 = krixik.create_pipeline(name='list_method_1_summarize',\n",
    "                                    module_chain=['summarize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process four files through the pipeline we just created.\n",
    "\n",
    "process_output_1 = pipeline_1.process(local_file_path=\"../../data/input/Frankenstein.txt\", # the initial local filepath where the input file is stored\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      symbolic_directory_path=\"/novels/gothic\",\n",
    "                                      file_name=\"Frankenstein.txt\",\n",
    "                                      file_tags=[{\"author\": \"Shelley\"}, {\"category\": \"gothic\"}, {\"century\": 19}])\n",
    "\n",
    "process_output_2 = pipeline_1.process(local_file_path=\"../../data/input/Pride and Prejudice.txt\", # the initial local filepath where the input file is stored\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      symbolic_directory_path=\"/novels/romance\",\n",
    "                                      file_name=\"Pride and Prejudice.txt\",\n",
    "                                      file_tags=[{\"author\": \"Austen\"}, {\"category\": \"romance\"}, {\"century\": 19}])\n",
    "\n",
    "process_output_3 = pipeline_1.process(local_file_path=\"../../data/input/Moby Dick.txt\", # the initial local filepath where the input file is stored\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      symbolic_directory_path=\"/novels/adventure\",\n",
    "                                      file_name=\"Moby Dick.txt\",\n",
    "                                      file_tags=[{\"author\": \"Melville\"}, {\"category\": \"adventure\"}, {\"century\": 19}])\n",
    "\n",
    "process_output_4 = pipeline_1.process(local_file_path=\"../../data/input/Little Women.txt\", # the initial local filepath where the input file is stored\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      symbolic_directory_path=\"/novels/bildungsroman\",\n",
    "                                      file_name=\"Little Women.txt\",\n",
    "                                      file_tags=[{\"author\": \"Alcott\"}, {\"category\": \"bildungsroman\"}, {\"century\": 19}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at what the output for the four of these looks like. The first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"examples-transcribe-multilingual-sentiment-docs\",\n",
      "  \"request_id\": \"1119f07f-e4a1-4021-9668-2f19ea367568\",\n",
      "  \"file_id\": \"efdc2954-9bef-4427-8de1-2bd18a830015\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id efdc2954-9bef-4427-8de1-2bd18a830015.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"For the starting position, we want to see the feed between the hip and shoulders width, the heels on the floor, a neutral column mediated by abdominal tension, the shoulders are lightly in front of the bar or above, straight arms, symmetrical hands and enough width to not rather the knees and we can have a lightly look forward.\",\n",
      "      \"positive\": 0.99,\n",
      "      \"negative\": 0.01,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"To perform the movement, our athlete will push from the heels, he will start to raise the hips and shoulders together, when the bar passes the knees, we extend the hip.\",\n",
      "      \"positive\": 0.996,\n",
      "      \"negative\": 0.004,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"For return, we are going to delay the push of the knees and we are going to push the hip back and the chess forward.\",\n",
      "      \"positive\": 0.006,\n",
      "      \"negative\": 0.994,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"When the bar passes the knees, we have the correct angle of our trunk and we already blessed the knees to approximately half the hip for starting position and resting.\",\n",
      "      \"positive\": 0.493,\n",
      "      \"negative\": 0.507,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Throughout the movement, we want to see the bar close to the body when going up and down.\",\n",
      "      \"positive\": 0.972,\n",
      "      \"negative\": 0.028,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik/code/krixik-docs/docs/examples/transcribe/efdc2954-9bef-4427-8de1-2bd18a830015.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of the first process\n",
    "\n",
    "print(json.dumps(process_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicely print the output of the second process\n",
    "\n",
    "print(json.dumps(process_output_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicely print the output of the third process\n",
    "\n",
    "print(json.dumps(process_output_3, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the fourth one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicely print the output of the fourth process\n",
    "\n",
    "print(json.dumps(process_output_4, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `file_ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try listing by `file_ids`.\n",
    "\n",
    "You have the `file_id` of each of the four files you processed; each was returned after processing finalized. Remember that you can list by multiple `file_id`s if you so choose, and it's easy to do so because `file_ids` is submitted in list format.\n",
    "\n",
    "Listing for the <u>Frankenstein</u> and <u>Moby Dick</u> files is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"11dcf756-702c-421c-a85a-49dabc2cca7f\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via file_ids\n",
    "\n",
    "list_output_1 = pipeline_1.list(file_ids=[\"XXXXX\", \"YYYY\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(list_output_1, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `file_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list via `file_name`s. It works just like listing with `file_id`s above, but with `file_name` instead of `file_id`. We'll list <u>Pride and Prejudice</u> via `file_names`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .list records for one of the uploaded files via file_names\n",
    "\n",
    "list_output_2 = pipeline_1.list(file_names=[\"Pride and Prejudice.txt\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `symbolic_directory_paths`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list via `symbolic_directory_paths`. It works just like listing with `file_id`s and `file_name`s above, but with `symbolic_directory_path` instead. We'll list <u>Little Women</u> and <u>Moby Dick</u> via `symbolic_directory_paths`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"70c71a76-7ce9-43c7-86e7-838b7fa93d8e\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via symbolic_directory_paths\n",
    "\n",
    "list_output_3 = pipeline_1.list(file_names=[\"/novels/bildungsroman\", \"/novels/adventure\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(list_output_3, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a full record for each file was returned. To learn more about each metadata item, visit the documentation for the [`.process`](../parameters_processing_files_through_pipelines/process_method.md) method, where they are gone into detail on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing by `file_tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list through `file_tags`.  We'll list for 19th century novels and any novels by 'Alcott', as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"7915929d-47cc-4fb9-82f6-b737ad823458\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list records for two of the uploaded files via symbolic_directory_paths\n",
    "\n",
    "list_output_4 = pipeline_1.list(file_tags=[{\"author\": \"alcott\"}, {\"century\": 19}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "\n",
    "print(json.dumps(list_output_4, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that every file included the file tag `{\"century\": 19}` when initially processed, all four files were listed. <u>Little Women</u> also included the file tag `{\"author\": \"alcott\"}`, but there's no duplication of results, so that file's record is only listed once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing by `created_at` and `updated_at` Bookend Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to `.list` by timestamp bookends, let's first [`.process`](../system/parameters_processing_files_through_pipelines/process_method.md) one additional file through our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"d3bca30e-d260-4c62-8aa9-91307b21d8b1\",\n",
      "  \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 3b941b6f-bd05-4fbb-83fd-6fea80c25629.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./3b941b6f-bd05-4fbb-83fd-6fea80c25629.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# process an additional file into earlier pipeline\n",
    "\n",
    "process_output_4 = pipeline_1.process(local_file_path=\"../../data/input/A Tale of Two Cities.txt\", # the initial local filepath where the input JSON file is stored\n",
    "                                      expire_time=60 * 30,  # process data will be deleted from the Krixik system in 30 minutes\n",
    "                                      wait_for_process=True,  # do not wait for process to complete before returning IDE control to user\n",
    "                                      verbose=False,  # do not display process update printouts upon running code\n",
    "                                      symbolic_directory_path=\"/novels/historical\",\n",
    "                                      file_name=\"A Tale of Two Cities.txt\",\n",
    "                                      file_tags=[{\"author\": \"Dickens\"}, {\"category\": \"hisorical\"}, {\"century\": 19}])\n",
    "\n",
    "process_output_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing by timestamp bookends is as straightforward as doing it by file system metadata. The following example only uses one type of bookend—`last_updated_start`—but all of them work the same way.\n",
    "\n",
    "Based on the output from the file we just processed and the output from the four earlier files, we'll choose a time/date that falls in the middle of all five `last_updated` timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"aacbb5e9-4701-454b-be2d-16d0f812a201\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:21\",\n",
      "      \"process_id\": \"132561f2-336b-c889-ba9e-500df80fdd38\",\n",
      "      \"created_at\": \"2024-04-26 21:05:21\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"pipeline_ordered_modules\": [\n",
      "          \"parser\"\n",
      "        ],\n",
      "        \"pipeline_output_process_keys\": [\n",
      "          \"snippet\"\n",
      "        ]\n",
      "      },\n",
      "      \"file_tags\": [],\n",
      "      \"file_description\": \"\",\n",
      "      \"symbolic_directory_path\": \"/etc\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:21\",\n",
      "      \"file_name\": \"krixik_generated_file_name_zqdsvltyrw.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# .list process records by last_updated timestamp bookend\n",
    "\n",
    "list_output_5 = pipeline_1.list(created_at_start=\"XXXX\")\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_5, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that timestamp bookend arguments operate with **AND** logic: to be listed, a file _must_ fall within the specified timestamp window. This also means that if two timestamp arguments are provided and there is no overlap between them, the `.list` method will return nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildcard Operator * Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the wildcard operator * to `.list` records whose exact metadata you don't remember—or if you wish to `.list` records for a group of files that share similar metadata.\n",
    "\n",
    "For `file_names`, `symbolic_directory_paths`, and `symbolic_file_paths` a wildcard may be used as either prefix or suffix:\n",
    "\n",
    "- Example * as a prefix: `*report.txt`\n",
    "- Example * as a suffix: `/home/files/studies*`\n",
    "\n",
    "For `file_tags` a wildcard may be used for as the value in a key-value pair dictionary. This will return all records with the corresponding key.\n",
    "\n",
    "- Example * in file_tags: `{\"invoice_type\": \"*\"}`\n",
    "\n",
    "Let's dig into `.list` method examples for each of these. First a prefix wildcard in `file_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"341c4e07-62a6-47f0-904b-7ff2ee3bbaef\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a wildcard prefix in file_names\n",
    "\n",
    "list_output_6 = pipeline_1.list(file_names=[\"*e.txt\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_6, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file whose `file_name` ends with \"e.txt\".\n",
    "\n",
    "Now a suffix wildcard in `symbolic_directory_paths`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b6d53064-2748-4c3a-ac7a-e0325cf8c58f\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard suffix in symbolic_directory_paths\n",
    "\n",
    "list_output_7 = pipeline_1.list(symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_7, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file whose `symbolic_directory_path` begins with \"/my/\".\n",
    "\n",
    "Now a wildcard operator in `file_tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"de17823f-5601-4143-b2ae-c546c173cdc7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_tags_keys\": [\n",
      "            \"author\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using the wildcard operator in file_tags\n",
    "\n",
    "list_output_8 = pipeline_1.list(file_tags=[{\"author\": \"*\"}])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_8, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will return records for every file that has a file_tag whose key is \"author\", regardless of the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Global Root\n",
    "\n",
    "As you might have surmised, there is one very special use of the wildcard operator on `symbolic_directory_path`s: we call it \"the global root\". It's leveraged by placing a wildcard operator * right after the root slash, and having nothing else, as follows:\n",
    "\n",
    "```python\n",
    "# example line of code with the global root\n",
    "symbolic_directory_paths=['/*']\n",
    "```\n",
    "\n",
    "Listing the global root returns records for every single file in your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multiple Arguments with the `.list` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As earlier mentioned, you can jointly use multiple input arguments with the `.list` method. Multiple inputs are combined in a logical **OR** (if they are metadata arguments) or **AND** (if they are timestamp bookends) to retrieve records satisfying what's been requested.\n",
    "\n",
    "As an example, let's combine a timestamp bookend, a `symbolic_file_path`, and `file_tags` in one `.list` method invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"091a2b5e-4d2f-44cd-9fcf-65a0c80546b7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a combination of input args\n",
    "\n",
    "list_output_9 = pipeline_1.list(created_at_end=XXXX,\n",
    "                                symbolic_file_path=\"/novels/gothic/Pride and Prejudice.txt\",\n",
    "                                file_tags=[({\"author\":\"Alcott\"})])\n",
    "\n",
    "# nicely print the output of this .list\n",
    "\n",
    "print(json.dumps(list_output_9, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although <u>Pride and Prejudice</u> and <u>Little Women</u> are respectively covered by the `symbolic_file_paths` and `file_tags` arguments, neither of them falls within the indicated timestamp window. Consequently, they are both excluded from the above result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "\n",
    "reset_pipeline(pipeline_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
